# electre_tri_nutriscore.py - Version simplifi√©e
import pandas as pd
import numpy as np
import ast
import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# =============================================================================
# CONFIGURATION
# =============================================================================
INPUT_XLSX = "collecte_de_donnee_projet/utils/combined_spreads_data.xlsx"
OUTPUT_XLSX = "electre_tri_resultats.xlsx"

# Crit√®res ELECTRE TRI - Poids √©quilibr√©s pour meilleure discrimination
CRITERIA = {
    "energy-kcal_100g": {"direction": "cost", "weight": 0.12},      # √ânergie - importance mod√©r√©e
    "sugars_100g": {"direction": "cost", "weight": 0.12},      # Sucres - r√©duit pour √©viter sur-p√©nalisation  
    "fat_100g": {"direction": "cost", "weight": 0.12}, # Graisses satur√©es - r√©duit
    "sodium_100g": {"direction": "cost", "weight": 0.08},      # Sodium - moins important pour p√¢tes √† tartiner
    "fruits_vegetables_nuts_100g": {"direction": "benefit", "weight": 0.18}, # Noix/fruits - tr√®s important !
    "fiber_100g": {"direction": "benefit", "weight": 0.15},    # Fibres - valoris√©es
    "proteins_100g": {"direction": "benefit", "weight": 0.13}, # Prot√©ines - augment√©es
    "additives_n": {"direction": "cost", "weight": 0.10}       # Additifs - conserv√©
}
# Total: cost = 0.54, benefit = 0.46 (plus √©quilibr√©)

# Classes ELECTRE TRI (5 classes de A' √† E')
CLASSES = ["A'", "B'", "C'", "D'", "E'"]  # A' = excellent, E' = √† √©viter

# Seuils majoritaires selon les exigences du projet
LAMBDA_VALUES = [0.6, 0.7]  # Œª=0.6 pour optimiste, Œª=0.7 pour pessimiste

# =============================================================================
# PROFILS LIMITES (b1 √† b6) - CALIBR√âS SUR DONN√âES NETTOY√âES
# =============================================================================
# Rappel de la logique selon le projet (Page 10) :
# b6 = Borne Sup√©rieure (Perfection inatteignable, pour fermer le mod√®le)
# b5 = Fronti√®re A'/B' (Excellence nutritionnelle)
# b4 = Fronti√®re B'/C' (Bon produit)
# b3 = Fronti√®re C'/D' (Produit moyen/standard)
# b2 = Fronti√®re D'/E' (Produit √† limiter fortement)
# b1 = Borne Inf√©rieure (Pire que le pire produit, pour fermer le mod√®le)

DEFAULT_PROFILES = [
    # --- b1 : Borne Inf√©rieure (Pire Cauchemar - INATTEIGNABLE) ---
    # Valeurs pires que tes max observ√©s (Sodium > 40, Sucre > 90)
    {"energy-kcal_100g": 1000, "sugars_100g": 101, "fat_100g": 101, "sodium_100g": 100,
     "fruits_vegetables_nuts_100g": -1, "fiber_100g": -1, "proteins_100g": -1, "additives_n": 50},

    # --- b2 : Fronti√®re E' / D' (Le seuil "Rouge") ---
    # Tes graphiques montrent que bcp de produits sont entre 500-600 kcal.
    # On s√©vit ici : si > 600 kcal ou > 35g sucre, c'est E.
    {"energy-kcal_100g": 600, "sugars_100g": 35, "fat_100g": 20, "sodium_100g": 1.5,
     "fruits_vegetables_nuts_100g": 0, "fiber_100g": 1.0, "proteins_100g": 2.0, "additives_n": 6},

    # --- b3 : Fronti√®re D' / C' (Le seuil "Jaune") ---
    # Moyenne gamme. Correspond au "ventre mou" de tes courbes.
    {"energy-kcal_100g": 480, "sugars_100g": 20, "fat_100g": 10, "sodium_100g": 0.5,
     "fruits_vegetables_nuts_100g": 10, "fiber_100g": 2.5, "proteins_100g": 4.0, "additives_n": 4},

    # --- b4 : Fronti√®re C' / B' (Le seuil "Vert Clair") ---
    # On commence √† √™tre exigeant. Moins de 10g de sucre (rare dans tes donn√©es -> valorisant).
    {"energy-kcal_100g": 350, "sugars_100g": 10, "fat_100g": 5, "sodium_100g": 0.2,
     "fruits_vegetables_nuts_100g": 40, "fiber_100g": 4.0, "proteins_100g": 6.0, "additives_n": 2},

    # --- b5 : Fronti√®re B' / A' (L'Excellence "Vert Fonc√©") ---
    # Tr√®s peu calorique, tr√®s naturel.
    # Note: Sodium √† 0.05 car ta courbe montre que bcp de produits sont √† 0.
    {"energy-kcal_100g": 200, "sugars_100g": 5, "fat_100g": 2, "sodium_100g": 0.05,
     "fruits_vegetables_nuts_100g": 80, "fiber_100g": 7.0, "proteins_100g": 9.0, "additives_n": 0},

    # --- b6 : Borne Sup√©rieure (Perfection Absolue - INATTEIGNABLE) ---
    # Inatteignable par d√©finition.
    {"energy-kcal_100g": -1, "sugars_100g": -1, "fat_100g": -1, "sodium_100g": -1,
     "fruits_vegetables_nuts_100g": 101, "fiber_100g": 101, "proteins_100g": 101, "additives_n": -1}
]

# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================
def get_column_values(df, column_name):
    """R√©cup√®re les valeurs d'une colonne et les convertit en nombres."""
    if column_name in df.columns:
        # Convertir en nombres, mettre 0 si impossible
        values = pd.to_numeric(df[column_name], errors='coerce').fillna(0)
        return values
    else:
        # Si la colonne n'existe pas, cr√©er une s√©rie de z√©ros
        return pd.Series([0] * len(df))

def extract_criteria_values(df):
    """Extrait les valeurs nutritionnelles pour chaque crit√®re ELECTRE TRI."""
    print("üîç Extraction des crit√®res nutritionnels...")
    
    # CORRECTION: Vos colonnes ont d√©j√† les bons noms !
    # Mapping direct : crit√®re ELECTRE ‚Üí nom de colonne dans votre fichier
    colonnes = {
        "energy-kcal_100g": "energy-kcal_100g",              # ‚úÖ Existe d√©j√†
        "sugars_100g": "sugars_100g",                        # ‚úÖ Existe d√©j√†
        "fat_100g": "fat_100g",                              # ‚úÖ Existe d√©j√†
        "sodium_100g": "sodium_100g",                        # ‚úÖ Existe d√©j√†
        "fruits_vegetables_nuts_100g": "fruits_vegetables_nuts_100g",  # ‚úÖ Existe d√©j√†
        "fiber_100g": "fiber_100g",                          # ‚úÖ Existe d√©j√†
        "proteins_100g": "proteins_100g",                    # ‚úÖ Existe d√©j√†
        "additives_n": "additives_n"                         # ‚úÖ Existe d√©j√†
    }
    
    # Cr√©er un nouveau DataFrame avec les crit√®res
    criteres_data = {}
    
    print("üìã V√©rification des colonnes dans le fichier:")
    print(f"   Colonnes disponibles: {list(df.columns)}")
    
    for critere, nom_colonne in colonnes.items():
        # R√©cup√©rer les valeurs de chaque crit√®re
        valeurs = get_column_values(df, nom_colonne)
        criteres_data[critere] = valeurs
        
        # Afficher le r√©sultat avec statistiques
        if nom_colonne in df.columns:
            nb_non_nulles = (valeurs != 0).sum()
            nb_nulles = (valeurs == 0).sum()
            print(f"  ‚úÖ {critere} trouv√© dans '{nom_colonne}': {nb_non_nulles} valeurs, {nb_nulles} z√©ros")
        else:
            print(f"  ‚ùå {critere} non trouv√©, cr√©ation avec valeurs par d√©faut (0)")
    
    return pd.DataFrame(criteres_data)

def safe_eval(x):
    """Convertit une cha√Æne en dictionnaire de mani√®re s√ªre."""
    if isinstance(x, dict):
        return x
    if pd.isna(x):
        return {}
    try:
        return ast.literal_eval(str(x))
    except:
        try:
            return json.loads(str(x))
        except:
            return {}

# =============================================================================
# ALGORITHME ELECTRE TRI - COEUR DE LA M√âTHODE
# =============================================================================

def calculate_concordance(product_values, profile_values):
    """
    Calcule si un produit est meilleur qu'un profil de r√©f√©rence.
    
    Retourne un score entre 0 et 1 :
    - Plus proche de 1 = le produit d√©passe le profil sur la plupart des crit√®res
    - Plus proche de 0 = le produit ne d√©passe pas le profil
    """
    total_score = 0.0
    
    # V√©rifier chaque crit√®re un par un
    for critere_nom, critere_config in CRITERIA.items():
        poids = critere_config["weight"]  # Importance du crit√®re
        type_critere = critere_config["direction"]  # "benefit" ou "cost"
        
        # Valeurs du produit et du profil pour ce crit√®re
        valeur_produit = product_values.get(critere_nom, 0)
        valeur_profil = profile_values.get(critere_nom, 0)
        
        # V√©rifier si le produit est meilleur que le profil
        if type_critere == "benefit":  
            # Pour les bons crit√®res (fibres, prot√©ines...) : plus = mieux
            produit_meilleur = valeur_produit >= valeur_profil
        else:  
            # Pour les mauvais crit√®res (sucres, graisses...) : moins = mieux
            produit_meilleur = valeur_produit <= valeur_profil
            
        # Si le produit est meilleur, ajouter le poids au score total
        if produit_meilleur:
            total_score += poids
    
    return total_score

def classify_pessimistic(product_values, profiles, seuil_majorite):
    """
    Classification pessimiste : commence par les profils les plus hauts.
    CORRIG√â: Attribution correcte des classes selon les bornes b1-b6
    """
    # Commencer par le profil le plus √©lev√© (b5) et descendre vers (b2)
    # b6 et b1 sont des bornes inatteignables, on ne les teste pas
    for numero_profil in range(5, 1, -1):  # 5, 4, 3, 2 (b5, b4, b3, b2)
        profil = profiles[numero_profil - 1]  # Liste commence √† 0
        
        # Calculer si le produit d√©passe ce profil
        score = calculate_concordance(product_values, profil)
        
        if score >= seuil_majorite:
            # Le produit d√©passe le profil, on l'affecte √† la classe SUP√âRIEURE
            if numero_profil == 5: return "A'"    # D√©passe b5 ‚Üí Excellence
            elif numero_profil == 4: return "B'"  # D√©passe b4 ‚Üí Tr√®s bon
            elif numero_profil == 3: return "C'"  # D√©passe b3 ‚Üí Bon  
            elif numero_profil == 2: return "D'"  # D√©passe b2 ‚Üí Moyen
    
    # Si le produit ne d√©passe aucun profil (m√™me pas b2), c'est le plus mauvais
    return "E'"

def classify_optimistic(product_values, profiles, seuil_majorite):
    """
    Classification optimiste conforme au Slide 13 (utilise la Pr√©f√©rence Stricte P).
    """
    # On monte de b2 vers b5 (œÄ2 vers œÄ5 dans les slides)
    # Rappel: profiles[0] est b1, profiles[1] est b2...
    for numero_profil in range(2, 6): 
        profil = profiles[numero_profil - 1] 
        
        # 1. Est-ce que le Profil Surclasse le Produit ? (b S a)
        score_profil_sur_produit = calculate_concordance(profil, product_values)
        b_S_a = score_profil_sur_produit >= seuil_majorite
        
        # 2. Est-ce que le Produit Surclasse le Profil ? (a S b)
        score_produit_sur_profil = calculate_concordance(product_values, profil)
        a_S_b = score_produit_sur_profil >= seuil_majorite
        
        # 3. Pr√©f√©rence Stricte (b P a) <=> (b S a) ET NON (a S b)
        b_P_a = b_S_a and not a_S_b
        
        if b_P_a:
            # Le profil est STRICTEMENT meilleur que le produit.
            # Le produit ne peut pas appartenir √† cette cat√©gorie sup√©rieure, il tombe dans celle d'en dessous.
            if numero_profil == 2: return "E'"    # Stopp√© par b2
            elif numero_profil == 3: return "D'"  # Stopp√© par b3
            elif numero_profil == 4: return "C'"
            elif numero_profil == 5: return "B'"
            
    # Si aucun profil n'est strictement meilleur, c'est le top
    return "A'"

def compare_with_nutriscore(df_results):
    """
    Compare les classifications ELECTRE TRI avec le Nutri-Score original.
    
    Args:
        df_results: DataFrame avec les r√©sultats ELECTRE TRI
    
    Returns:
        dict: statistiques de comparaison et matrices de confusion
    """
    # Mapping Nutri-Score vers nos classes ELECTRE TRI
    nutriscore_mapping = {'A': "A'", 'B': "B'", 'C': "C'", 'D': "D'", 'E': "E'"}
    
    stats = {}
    
    for lambda_val in LAMBDA_VALUES:
        df_lambda = df_results[df_results['lambda'] == lambda_val]
        
        # Mapper le Nutri-Score original
        df_lambda = df_lambda.copy()
        df_lambda['nutriscore_mapped'] = df_lambda['nutriscore_original'].map(nutriscore_mapping)
        
        # Filtrer les produits avec un Nutri-Score valide
        df_valid = df_lambda.dropna(subset=['nutriscore_mapped'])
        
        if len(df_valid) > 0:
            # Comparaisons simples
            accord_pessimiste = (df_valid['classe_pessimiste'] == df_valid['nutriscore_mapped']).sum()
            accord_optimiste = (df_valid['classe_optimiste'] == df_valid['nutriscore_mapped']).sum()
            
            total = len(df_valid)
            
            # === MATRICES DE CONFUSION ===
            # Matrice pour pessimiste
            confusion_pessimiste = pd.crosstab(
                df_valid['nutriscore_mapped'], 
                df_valid['classe_pessimiste'], 
                rownames=['Nutri-Score'], 
                colnames=['ELECTRE TRI Pessimiste'],
                margins=True
            )
            
            # Matrice pour optimiste
            confusion_optimiste = pd.crosstab(
                df_valid['nutriscore_mapped'], 
                df_valid['classe_optimiste'], 
                rownames=['Nutri-Score'], 
                colnames=['ELECTRE TRI Optimiste'],
                margins=True
            )
            
            stats[f'lambda_{lambda_val}'] = {
                'total_produits': total,
                'accord_pessimiste': accord_pessimiste,
                'accord_optimiste': accord_optimiste,
                'taux_accord_pessimiste': round(accord_pessimiste / total * 100, 1),
                'taux_accord_optimiste': round(accord_optimiste / total * 100, 1),
                'desaccord_pessimiste': total - accord_pessimiste,
                'desaccord_optimiste': total - accord_optimiste,
                'matrice_confusion_pessimiste': confusion_pessimiste,
                'matrice_confusion_optimiste': confusion_optimiste
            }
    
    return stats

def generate_visualizations(df_results, comparison_stats, output_dir="graphiques"):
    """
    G√©n√®re les graphiques et visualisations pour l'analyse ELECTRE TRI.
    
    Args:
        df_results: DataFrame avec les r√©sultats ELECTRE TRI
        comparison_stats: statistiques de comparaison avec Nutri-Score
        output_dir: dossier de sortie pour les graphiques
    """
    # Cr√©er le dossier de sortie
    Path(output_dir).mkdir(exist_ok=True)
    
    # Configuration matplotlib
    plt.style.use('default')
    plt.rcParams['figure.figsize'] = (12, 8)
    plt.rcParams['font.size'] = 10
    
    # === 1. R√âPARTITION DES CLASSIFICATIONS ===
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('R√©partition des Classifications ELECTRE TRI', fontsize=16, fontweight='bold')
    
    for idx, lambda_val in enumerate(LAMBDA_VALUES):
        df_lambda = df_results[df_results['lambda'] == lambda_val]
        
        # Pessimiste
        pess_counts = df_lambda['classe_pessimiste'].value_counts()
        axes[idx, 0].pie(pess_counts.values, labels=pess_counts.index, autopct='%1.1f%%', 
                        colors=['#2E8B57', '#32CD32', '#FFD700', '#FF8C00', '#DC143C'])
        axes[idx, 0].set_title(f'Pessimiste Œª={lambda_val}')
        
        # Optimiste
        opt_counts = df_lambda['classe_optimiste'].value_counts()
        axes[idx, 1].pie(opt_counts.values, labels=opt_counts.index, autopct='%1.1f%%',
                        colors=['#2E8B57', '#32CD32', '#FFD700', '#FF8C00', '#DC143C'])
        axes[idx, 1].set_title(f'Optimiste Œª={lambda_val}')
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/repartition_classifications.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # === 2. COMPARAISON PESSIMISTE VS OPTIMISTE ===
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    lambda_labels = [f'Œª={lam}' for lam in LAMBDA_VALUES]
    x = np.arange(len(lambda_labels))
    
    pess_counts = []
    opt_counts = []
    
    for lambda_val in LAMBDA_VALUES:
        df_lambda = df_results[df_results['lambda'] == lambda_val]
        pess_counts.append(df_lambda['classe_pessimiste'].value_counts().to_dict())
        opt_counts.append(df_lambda['classe_optimiste'].value_counts().to_dict())
    
    # Cr√©er un graphique en barres group√©es
    width = 0.35
    classes = CLASSES
    colors = ['#2E8B57', '#32CD32', '#FFD700', '#FF8C00', '#DC143C']
    
    bottom_pess = np.zeros(len(lambda_labels))
    bottom_opt = np.zeros(len(lambda_labels))
    
    for i, class_name in enumerate(classes):
        pess_vals = [pess_counts[j].get(class_name, 0) for j in range(len(lambda_labels))]
        opt_vals = [opt_counts[j].get(class_name, 0) for j in range(len(lambda_labels))]
        
        ax.bar(x - width/2, pess_vals, width, bottom=bottom_pess, 
               label=f'{class_name} (Pess)', color=colors[i], alpha=0.8)
        ax.bar(x + width/2, opt_vals, width, bottom=bottom_opt,
               label=f'{class_name} (Opt)', color=colors[i], alpha=0.5)
        
        bottom_pess += pess_vals
        bottom_opt += opt_vals
    
    ax.set_xlabel('Seuil Lambda')
    ax.set_ylabel('Nombre de produits')
    ax.set_title('Comparaison Pessimiste vs Optimiste par Seuil Lambda')
    ax.set_xticks(x)
    ax.set_xticklabels(lambda_labels)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/comparaison_pessimiste_optimiste.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # === 3. MATRICES DE CONFUSION GRAPHIQUES ===
    if comparison_stats:
        for lambda_key, stats in comparison_stats.items():
            lambda_val = lambda_key.split('_')[1]
            
            # Matrice de confusion Pessimiste
            fig, ax = plt.subplots(1, 1, figsize=(10, 8))
            confusion_pess = stats['matrice_confusion_pessimiste'].iloc[:-1, :-1]  # Exclure les totaux
            
            sns.heatmap(confusion_pess, annot=True, fmt='d', cmap='Blues', 
                       ax=ax, cbar_kws={'label': 'Nombre de produits'})
            ax.set_title(f'Matrice de Confusion - Pessimiste (Œª={lambda_val})')
            ax.set_xlabel('ELECTRE TRI Pr√©diction')
            ax.set_ylabel('Nutri-Score R√©el')
            
            plt.tight_layout()
            plt.savefig(f'{output_dir}/confusion_pessimiste_lambda_{lambda_val.replace(".", "_")}.png', 
                       dpi=300, bbox_inches='tight')
            plt.close()
            
            # Matrice de confusion Optimiste
            fig, ax = plt.subplots(1, 1, figsize=(10, 8))
            confusion_opt = stats['matrice_confusion_optimiste'].iloc[:-1, :-1]  # Exclure les totaux
            
            sns.heatmap(confusion_opt, annot=True, fmt='d', cmap='Oranges',
                       ax=ax, cbar_kws={'label': 'Nombre de produits'})
            ax.set_title(f'Matrice de Confusion - Optimiste (Œª={lambda_val})')
            ax.set_xlabel('ELECTRE TRI Pr√©diction')
            ax.set_ylabel('Nutri-Score R√©el')
            
            plt.tight_layout()
            plt.savefig(f'{output_dir}/confusion_optimiste_lambda_{lambda_val.replace(".", "_")}.png',
                       dpi=300, bbox_inches='tight')
            plt.close()
    
    # === 4. TAUX D'ACCORD AVEC NUTRI-SCORE ===
    if comparison_stats:
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        
        lambdas = []
        taux_pess = []
        taux_opt = []
        
        for lambda_key, stats in comparison_stats.items():
            lambda_val = lambda_key.split('_')[1]
            lambdas.append(f'Œª={lambda_val}')
            taux_pess.append(stats['taux_accord_pessimiste'])
            taux_opt.append(stats['taux_accord_optimiste'])
        
        x = np.arange(len(lambdas))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, taux_pess, width, label='Pessimiste', 
                      color='#4169E1', alpha=0.8)
        bars2 = ax.bar(x + width/2, taux_opt, width, label='Optimiste',
                      color='#FF6347', alpha=0.8)
        
        # Ajouter les valeurs sur les barres
        for bar in bars1:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                   f'{height:.1f}%', ha='center', va='bottom')
        
        for bar in bars2:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                   f'{height:.1f}%', ha='center', va='bottom')
        
        ax.set_xlabel('Seuil Lambda')
        ax.set_ylabel('Taux d\'accord (%)')
        ax.set_title('Taux d\'accord avec le Nutri-Score par M√©thode et Seuil')
        ax.set_xticks(x)
        ax.set_xticklabels(lambdas)
        ax.legend()
        ax.set_ylim(0, 100)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/taux_accord_nutriscore.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    # === 5. DISTRIBUTION DES CRIT√àRES ===
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    fig.suptitle('Distribution des Valeurs des Crit√®res', fontsize=16, fontweight='bold')
    
    axes = axes.flatten()
    for idx, (criterion, config) in enumerate(CRITERIA.items()):
        df_unique = df_results[df_results['lambda'] == LAMBDA_VALUES[0]]  # Prendre une seule fois
        values = df_unique[criterion]
        
        axes[idx].hist(values, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[idx].set_title(f'{criterion}\n({config["direction"]} criterion)')
        axes[idx].set_xlabel('Valeur')
        axes[idx].set_ylabel('Fr√©quence')
        axes[idx].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/distribution_criteres.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"üìä Graphiques sauvegard√©s dans le dossier '{output_dir}/'")
    return output_dir

# =============================================================================
# PIPELINE PRINCIPAL ELECTRE TRI
# =============================================================================

def clean_nutriscore_value(row):
    """Nettoie et valide une valeur de Nutri-Score."""
    if 'nutriscore_grade' in row and pd.notna(row['nutriscore_grade']):
        raw_value = str(row['nutriscore_grade']).strip().upper()
        # Ne garder que les vraies lettres Nutri-Score
        if raw_value in ['A', 'B', 'C', 'D', 'E']:
            return raw_value
    return 'N/A'  # Valeurs corrompues ‚Üí N/A

def classify_products(df, df_criteria, profiles):
    """Classifie tous les produits avec ELECTRE TRI."""
    results = []
    
    print(f"\nüî¢ Classification des {len(df)} produits...")
    
    # Selon les exigences du projet : Œª=0.6 optimiste, Œª=0.7 pessimiste
    for lambda_val in LAMBDA_VALUES:
        print(f"  Traitement avec seuil Œª = {lambda_val}")
        
        for idx, row in df.iterrows():
            # R√©cup√©rer les valeurs nutritionnelles du produit
            product_values = {}
            for critere in CRITERIA.keys():
                product_values[critere] = df_criteria.loc[idx, critere]
            
            # CORRECTION: Utiliser lambda_val pour voir la diff√©rence entre les seuils
            # Pour chaque valeur de lambda, appliquer aux DEUX m√©thodes
            classe_pessimiste = classify_pessimistic(product_values, profiles, lambda_val)
            classe_optimiste = classify_optimistic(product_values, profiles, lambda_val)
            
            # Nettoyer le Nutri-Score
            nutriscore_value = clean_nutriscore_value(row)
            
            # Sauvegarder le r√©sultat
            results.append({
                'product_name': row.get('product_name', f'Produit_{idx}'),
                'nutriscore_original': nutriscore_value,
                'lambda': lambda_val,  # Garder lambda_val pour la compatibilit√© des analyses
                'classe_pessimiste': classe_pessimiste,
                'classe_optimiste': classe_optimiste,
                **product_values
            })
    
    return pd.DataFrame(results)

def save_results_to_excel(df_results, profiles, output_file):
    """Sauvegarde les r√©sultats dans un fichier Excel."""
    print(f"\nüíæ Sauvegarde des r√©sultats dans {output_file}...")
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # Feuille principale
        df_results.to_excel(writer, sheet_name='Classifications_ELECTRE_TRI', index=False)
        
        # Feuilles par lambda
        for lambda_val in LAMBDA_VALUES:
            df_lambda = df_results[df_results['lambda'] == lambda_val]
            sheet_name = f'Lambda_{str(lambda_val).replace(".", "_")}'
            df_lambda.to_excel(writer, sheet_name=sheet_name, index=False)
        
        # Feuille des profils
        df_profiles = pd.DataFrame(profiles)
        df_profiles.index = [f'œÄ{i+1}' for i in range(len(profiles))]
        df_profiles.to_excel(writer, sheet_name='Profils_Limites')
        
        # Configuration des crit√®res
        df_config = pd.DataFrame.from_dict(CRITERIA, orient='index')
        df_config.to_excel(writer, sheet_name='Configuration_Criteres')

def print_comparison_results(comparison_stats):
    """Affiche les r√©sultats de comparaison avec le Nutri-Score."""
    for lambda_key, stats in comparison_stats.items():
        lambda_val = lambda_key.split('_')[1]
        print(f"\n  üìä Seuil Œª = {lambda_val} ({stats['total_produits']} produits avec Nutri-Score):")
        print(f"    üéØ Accord Pessimiste: {stats['accord_pessimiste']}/{stats['total_produits']} ({stats['taux_accord_pessimiste']}%)")
        print(f"    üéØ Accord Optimiste:  {stats['accord_optimiste']}/{stats['total_produits']} ({stats['taux_accord_optimiste']}%)")

def run_electre_tri(input_file=INPUT_XLSX, output_file=OUTPUT_XLSX, profiles=None):
    """Fonction principale : lance l'analyse ELECTRE TRI compl√®te."""
    print("üîÑ D√©but de l'analyse ELECTRE TRI")
    print(f"üìÇ Fichier d'entr√©e: {input_file}")
    
    # √âtape 1: Charger les donn√©es
    df = pd.read_excel(input_file)
    print(f"üìä {len(df)} produits charg√©s")
    
    # √âtape 2: Extraire les crit√®res nutritionnels
    df_criteria = extract_criteria_values(df)
    print(f"‚úÖ Crit√®res extraits: {list(df_criteria.columns)}")
    
    # √âtape 3: D√©finir les profils
    if profiles is None:
        profiles = DEFAULT_PROFILES
        print("‚öôÔ∏è  Utilisation des profils par d√©faut")
    
    # √âtape 4: Classifier tous les produits
    df_results = classify_products(df, df_criteria, profiles)
    
    # √âtape 5: Sauvegarder les r√©sultats
    save_results_to_excel(df_results, profiles, output_file)
    print(f"‚úÖ Analyse termin√©e ! R√©sultats sauvegard√©s dans {output_file}")
    
    # √âtape 6: Analyser les r√©sultats
    print("\nÔøΩ Comparaison avec le Nutri-Score original:")
    nutriscore_count = df_results['nutriscore_original'].value_counts()
    total_with_nutriscore = len(df_results[df_results['nutriscore_original'] != 'N/A'])
    print(f"    Total avec Nutri-Score valide: {total_with_nutriscore}")
    
    if total_with_nutriscore > 0:
        comparison_stats = compare_with_nutriscore(df_results)
        print_comparison_results(comparison_stats)
    
    # √âtape 7: Afficher la r√©partition des classes
    print("\nüìà R√©partition des classifications ELECTRE TRI:")
    for lambda_val in LAMBDA_VALUES:
        df_lambda = df_results[df_results['lambda'] == lambda_val]
        print(f"  Œª = {lambda_val}:")
        print(f"    Pessimiste: {df_lambda['classe_pessimiste'].value_counts().to_dict()}")
        print(f"    Optimiste:  {df_lambda['classe_optimiste'].value_counts().to_dict()}")
    
    # √âtape 8: G√©n√©rer les graphiques
    print("\nüìä G√©n√©ration des visualisations...")
    try:
        graphics_dir = generate_visualizations(df_results, comparison_stats if total_with_nutriscore > 0 else {})
        print(f"‚úÖ Graphiques cr√©√©s dans le dossier '{graphics_dir}/'")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de la g√©n√©ration des graphiques: {e}")
    
    return df_results

if __name__ == "__main__":
    # Lancement avec les param√®tres par d√©faut
    run_electre_tri()
    
    # Exemple d'utilisation avec profils personnalis√©s:
    # profils_custom = [
    #     {"energy-kcal_100g": 2500, "sugars_100g": 30, "fat_100g": 12, "sodium_100g": 2.0,
    #      "fruits_vegetables_nuts_100g": 0, "fiber_100g": 0, "proteins_100g": 1, "additives_n": 15},  # œÄ1
    #     {"energy-kcal_100g": 2000, "sugars_100g": 20, "fat_100g": 8, "sodium_100g": 1.2,
    #      "fruits_vegetables_nuts_100g": 10, "fiber_100g": 1, "proteins_100g": 3, "additives_n": 8}, # œÄ2
    #     # ... 4 autres profils complets
    # ]
    # run_electre_tri(profiles=profils_custom)